{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this demo, you'll see a more practical application of RNNs/LSTMs as character-level language models. The emphasis will be more on parallelization and using RNNs with data from Fuel.\n",
    "\n",
    "To get started, we first need to download the training text, validation text and a file that contains a dictionary for mapping characters to integers. We also need to import quite a list of modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import gzip\n",
    "\n",
    "import cPickle as pkl\n",
    "import time\n",
    "\n",
    "import numpy\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "from theano.tensor.nnet import categorical_crossentropy\n",
    "from theano import config\n",
    "from fuel.datasets import TextFile\n",
    "from fuel.streams import DataStream\n",
    "from fuel.schemes import ConstantScheme\n",
    "from fuel.transformers import Batch, Padding\n",
    "\n",
    "if not os.path.exists('traindata.txt'):\n",
    "    r = requests.get('http://www-etud.iro.umontreal.ca/~brakelp/traindata.txt.gz')\n",
    "    with open('traindata.txt.gz', 'wb') as data_file:\n",
    "        data_file.write(r.content)\n",
    "    with gzip.open('traindata.txt.gz', 'rb') as data_file:\n",
    "        with open('traindata.txt', 'w') as out_file:\n",
    "            out_file.write(data_file.read())\n",
    "        \n",
    "if not os.path.exists('valdata.txt'):\n",
    "    r = requests.get('http://www-etud.iro.umontreal.ca/~brakelp/valdata.txt.gz')\n",
    "    with open('valdata.txt.gz', 'wb') as data_file:\n",
    "        data_file.write(r.content)\n",
    "    with gzip.open('valdata.txt.gz', 'rb') as data_file:\n",
    "        with open('valdata.txt', 'w') as out_file:\n",
    "            out_file.write(data_file.read())\n",
    "\n",
    "if not os.path.exists('dictionary.pkl'):\n",
    "    r = requests.get('http://www-etud.iro.umontreal.ca/~brakelp/dictionary.pkl')\n",
    "    with open('dictionary.pkl', 'wb') as data_file:\n",
    "        data_file.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##The Model\n",
    "The code below shows an implementation of an LSTM network. Note that there are various different variations of the LSTM in use and this one doesn't include the so-called 'peephole connections'. We used a separate method for the dynamic update to make it easier to generate from the network later. The `index_dot` function doesn't safe much verbosity, but it clarifies that certain dot products have been replaced with indexing operations because this network will be applied to discrete data. Last but not least, note the addition of the `mask` argument which is used to ignore certain parts of the input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gauss_weight(ndim_in, ndim_out=None, sd=.005):\n",
    "    if ndim_out is None:\n",
    "        ndim_out = ndim_in\n",
    "    W = numpy.random.randn(ndim_in, ndim_out) * sd\n",
    "    return numpy.asarray(W, dtype=config.floatX)\n",
    "\n",
    "\n",
    "def index_dot(indices, w):\n",
    "    return w[indices.flatten()]\n",
    "\n",
    "\n",
    "class LstmLayer:\n",
    "\n",
    "    def __init__(self, rng, input, mask, n_in, n_h):\n",
    "\n",
    "        # Init params\n",
    "        self.W_i = theano.shared(gauss_weight(n_in, n_h), 'W_i', borrow=True)\n",
    "        self.W_f = theano.shared(gauss_weight(n_in, n_h), 'W_f', borrow=True)\n",
    "        self.W_c = theano.shared(gauss_weight(n_in, n_h), 'W_c', borrow=True)\n",
    "        self.W_o = theano.shared(gauss_weight(n_in, n_h), 'W_o', borrow=True)\n",
    "\n",
    "        self.U_i = theano.shared(gauss_weight(n_h), 'U_i', borrow=True)\n",
    "        self.U_f = theano.shared(gauss_weight(n_h), 'U_f', borrow=True)\n",
    "        self.U_c = theano.shared(gauss_weight(n_h), 'U_c', borrow=True)\n",
    "        self.U_o = theano.shared(gauss_weight(n_h), 'U_o', borrow=True)\n",
    "\n",
    "        self.b_i = theano.shared(numpy.zeros((n_h,), dtype=config.floatX),\n",
    "                                 'b_i', borrow=True)\n",
    "        self.b_f = theano.shared(numpy.zeros((n_h,), dtype=config.floatX),\n",
    "                                 'b_f', borrow=True)\n",
    "        self.b_c = theano.shared(numpy.zeros((n_h,), dtype=config.floatX),\n",
    "                                 'b_c', borrow=True)\n",
    "        self.b_o = theano.shared(numpy.zeros((n_h,), dtype=config.floatX),\n",
    "                                 'b_o', borrow=True)\n",
    "\n",
    "        self.params = [self.W_i, self.W_f, self.W_c, self.W_o,\n",
    "                       self.U_i, self.U_f, self.U_c, self.U_o,\n",
    "                       self.b_i, self.b_f, self.b_c, self.b_o]\n",
    "\n",
    "        outputs_info = [T.zeros((input.shape[1], n_h)),\n",
    "                        T.zeros((input.shape[1], n_h))]\n",
    "\n",
    "        rval, updates = theano.scan(self._step,\n",
    "                                    sequences=[mask, input],\n",
    "                                    outputs_info=outputs_info)\n",
    "\n",
    "        # self.output is in the format (length, batchsize, n_h)\n",
    "        self.output = rval[0]\n",
    "\n",
    "    def _step(self, m_, x_, h_, c_):\n",
    "\n",
    "        i_preact = (index_dot(x_, self.W_i) +\n",
    "                    T.dot(h_, self.U_i) + self.b_i)\n",
    "        i = T.nnet.sigmoid(i_preact)\n",
    "\n",
    "        f_preact = (index_dot(x_, self.W_f) +\n",
    "                    T.dot(h_, self.U_f) + self.b_f)\n",
    "        f = T.nnet.sigmoid(f_preact)\n",
    "\n",
    "        o_preact = (index_dot(x_, self.W_o) +\n",
    "                    T.dot(h_, self.U_o) + self.b_o)\n",
    "        o = T.nnet.sigmoid(o_preact)\n",
    "\n",
    "        c_preact = (index_dot(x_, self.W_c) +\n",
    "                    T.dot(h_, self.U_c) + self.b_c)\n",
    "        c = T.tanh(c_preact)\n",
    "\n",
    "        c = f * c_ + i * c\n",
    "        c = m_[:, None] * c + (1. - m_)[:, None] * c_\n",
    "\n",
    "        h = o * T.tanh(c)\n",
    "        h = m_[:, None] * h + (1. - m_)[:, None] * h_\n",
    "\n",
    "        return h, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block contains some code that computes cross-entropy for masked sequences and a stripped down version of the logistic regression class from the deep learning tutorials which we will need later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sequence_categorical_crossentropy(prediction, targets, mask):\n",
    "    prediction_flat = prediction.reshape(((prediction.shape[0] *\n",
    "                                           prediction.shape[1]),\n",
    "                                          prediction.shape[2]), ndim=2)\n",
    "    targets_flat = targets.flatten()\n",
    "    mask_flat = mask.flatten()\n",
    "    ce = categorical_crossentropy(prediction_flat, targets_flat)\n",
    "    return T.sum(ce * mask_flat)\n",
    "\n",
    "\n",
    "class LogisticRegression(object):\n",
    "   \n",
    "    def __init__(self, input, n_in, n_out):\n",
    "        \n",
    "        # initialize with 0 the weights W as a matrix of shape (n_in, n_out)\n",
    "        self.W = theano.shared(value=numpy.zeros((n_in, n_out),\n",
    "                                                 dtype=theano.config.floatX),\n",
    "                               name='W', borrow=True)\n",
    "        # initialize the baises b as a vector of n_out 0s\n",
    "        self.b = theano.shared(value=numpy.zeros((n_out,),\n",
    "                                                 dtype=theano.config.floatX),\n",
    "                               name='b', borrow=True)\n",
    "\n",
    "        # compute vector of class-membership probabilities in symbolic form\n",
    "        energy = T.dot(input, self.W) + self.b\n",
    "        energy_exp = T.exp(energy - T.max(energy, 2)[:, :, None])\n",
    "        pmf = energy_exp / energy_exp.sum(2)[:, :, None]\n",
    "        self.p_y_given_x = pmf\n",
    "        self.params = [self.W, self.b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Processing the Data\n",
    "The data in `traindata.txt` and `valdata.txt` is simply English text but formatted in such a way that every sentence is conveniently separated by the newline symbol. We'll use some of the functionality of fuel to perform the following preprocessing steps:\n",
    "* Convert everything to lowercase\n",
    "* Map characters to indices\n",
    "* Group the sentences into batches\n",
    "* Convert each batch in a matrix/tensor as long as the longest sequence with zeros padded to all the shorter sequences\n",
    "* Add a mask matrix that encodes the length of each sequence (a timestep at which the mask is 0 indicates that there is no data available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_epochs = 40\n",
    "n_h = 50\n",
    "DICT_FILE = 'dictionary.pkl'\n",
    "TRAIN_FILE = 'traindata.txt'\n",
    "VAL_FILE = 'valdata.txt'\n",
    "\n",
    "# Load the datasets with Fuel\n",
    "dictionary = pkl.load(open(DICT_FILE, 'r'))\n",
    "# add a symbol for unknown characters\n",
    "dictionary['~'] = len(dictionary)\n",
    "reverse_mapping = dict((j, i) for i, j in dictionary.items())\n",
    "\n",
    "train = TextFile(files=[TRAIN_FILE],\n",
    "                 dictionary=dictionary,\n",
    "                 unk_token='~',\n",
    "                 level='character',\n",
    "                 preprocess=str.lower,\n",
    "                 bos_token=None,\n",
    "                 eos_token=None)\n",
    "\n",
    "train_stream = DataStream.default_stream(train)\n",
    "\n",
    "# organize data in batches and pad shorter sequences with zeros\n",
    "train_stream = Batch(train_stream,\n",
    "                     iteration_scheme=ConstantScheme(batch_size))\n",
    "train_stream = Padding(train_stream)\n",
    "\n",
    "# idem dito for the validation text\n",
    "val = TextFile(files=[VAL_FILE],\n",
    "                 dictionary=dictionary,\n",
    "                 unk_token='~',\n",
    "                 level='character',\n",
    "                 preprocess=str.lower,\n",
    "                 bos_token=None,\n",
    "                 eos_token=None)\n",
    "\n",
    "val_stream = DataStream.default_stream(val)\n",
    "\n",
    "# organize data in batches and pad shorter sequences with zeros\n",
    "val_stream = Batch(val_stream,\n",
    "                     iteration_scheme=ConstantScheme(batch_size))\n",
    "val_stream = Padding(val_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##The Theano Graph\n",
    "We'll now define the complete Theano graph for computing costs and gradients among other things. The cost will be the cross-entropy of the next character in the sequence and the network will try to predict it based on the previous characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set the random number generator' seeds for consistency\n",
    "rng = numpy.random.RandomState(12345)\n",
    "\n",
    "x = T.lmatrix('x')\n",
    "mask = T.matrix('mask')\n",
    "\n",
    "# Construct an LSTM layer and a logistic regression layer\n",
    "recurrent_layer = LstmLayer(rng=rng, input=x, mask=mask, n_in=111, n_h=n_h)\n",
    "logreg_layer = LogisticRegression(input=recurrent_layer.output[:-1],\n",
    "                                  n_in=n_h, n_out=111)\n",
    "\n",
    "# define a cost variable to optimize\n",
    "cost = sequence_categorical_crossentropy(logreg_layer.p_y_given_x,\n",
    "                                         x[1:],\n",
    "                                         mask[1:]) / batch_size\n",
    "\n",
    "# create a list of all model parameters to be fit by gradient descent\n",
    "params = logreg_layer.params + recurrent_layer.params\n",
    "\n",
    "# create a list of gradients for all model parameters\n",
    "grads = T.grad(cost, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compile the function that updates the gradients. We also added a function that computes the cost without updating for monitoring purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pbrakel/Repositories/Theano/theano/scan_module/scan_perform_ext.py:117: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility\n",
      "  from scan_perform.scan_perform import *\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "updates = [\n",
    "    (param_i, param_i - learning_rate * grad_i)\n",
    "    for param_i, grad_i in zip(params, grads)\n",
    "]\n",
    "\n",
    "update_model = theano.function([x, mask], cost, updates=updates)\n",
    "\n",
    "evaluate_model = theano.function([x, mask], cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Generating Sequences\n",
    "To see if the networks learn something useful (and to make results monitoring more entertaining), we'll also write some code to generate sequences. For this, we'll first compile a function that computes a single state update for the network to have more control over the values of each variable at each time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_t = T.iscalar()\n",
    "h_p = T.vector()\n",
    "c_p = T.vector()\n",
    "h_t, c_t = recurrent_layer._step(T.ones(1), x_t, h_p, c_p)\n",
    "energy = T.dot(h_t, logreg_layer.W) + logreg_layer.b\n",
    "\n",
    "energy_exp = T.exp(energy - T.max(energy, axis=1, keepdims=True))\n",
    "\n",
    "output = energy_exp / energy_exp.sum(axis=1, keepdims=True)\n",
    "single_step = theano.function([x_t, h_p, c_p], [output, h_t, c_t])\n",
    "\n",
    "def speak(single_step, prefix='the meaning of life is ', n_steps=450):\n",
    "    try:\n",
    "        h_p = numpy.zeros((n_h,), dtype=config.floatX)\n",
    "        c_p = numpy.zeros((n_h,), dtype=config.floatX)\n",
    "        sentence = prefix\n",
    "        for char in prefix:\n",
    "            x_t = dictionary[char]\n",
    "            prediction, h_p, c_p = single_step(x_t, h_p.flatten(),\n",
    "                                               c_p.flatten())\n",
    "        # Renormalize probability in float64\n",
    "        flat_prediction = prediction.flatten()\n",
    "        flat_pred_sum = flat_prediction.sum(dtype='float64')\n",
    "        if flat_pred_sum > 1:\n",
    "            flat_prediction = flat_prediction.astype('float64') / flat_pred_sum\n",
    "        sample = numpy.random.multinomial(1, flat_prediction)\n",
    "\n",
    "        for i in range(n_steps):\n",
    "            x_t = numpy.argmax(sample)\n",
    "            prediction, h_p, c_p = single_step(x_t, h_p.flatten(),\n",
    "                                               c_p.flatten())\n",
    "            # Renormalize probability in float64\n",
    "            flat_prediction = prediction.flatten()\n",
    "            flat_pred_sum = flat_prediction.sum(dtype='float64')\n",
    "            if flat_pred_sum > 1:\n",
    "                flat_prediction = flat_prediction.astype('float64') / flat_pred_sum\n",
    "            sample = numpy.random.multinomial(1, flat_prediction)\n",
    "\n",
    "            sentence += reverse_mapping[x_t]\n",
    "\n",
    "        return sentence\n",
    "    except ValueError as e:\n",
    "        print 'Something went wrong during sentence generation: {}'.format(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "\n",
      "LSTM: \"the meaning of life is aoioif .�teb srnrswge isnvit aoser tko�  ag wio,�t semrap, em edsuvmee cal ile n � ped  tyinyah thbot ot nosedtr enou ugwgnattyyrp eeto t nol +he iug ic�rcjn  sg n� pta ha  bst  n hi rse gas l  mt at  rl a ttleeds� x ar  ds  ur. slt wnb  he mbtat tn^n�@s.s tlahhje l lns a   awi bmya;cewoa e ol� o$npt say ue on ehl hh td bdeu tso c  a tlmnhheapte! ndaa  b�osomo ieytm atid i i pgt �ot ,iasttconek�o. c  a  nlh gtsp ysat t no4 asi  �� spfhe a  n tiwi\"\n",
      "\n",
      "epoch: 0   minibatch: 40\n",
      "Average validation CE per sentence: 244.485689985\n",
      "\n",
      "LSTM: \"the meaning of life is t ayeeleg wallrn�d s wa ikuortoen shist bocaek ipasgatl re wanoh oovs ase aasth .ge ate teret pins io nhul te'e g ont oton iuu, m� tood] ict l� heteine th ougnr toy bo9tte ferd allthoav aor.p ci apy eeeioth mihs'atue yee woou,g f,t d ,uepffers totesgg icyonoj bpe tt id.mis thennf rar ie felwbse ald�orucabs thiiarm au,hl, vhdryatup2mre taicnh marim. mg n chohd�ysocd thal risrre�n f auosn& pe disane th a we unen, a teneel trufon tate iy thy te tipo\"\n",
      "\n",
      "epoch: 0   minibatch: 80\n",
      "Average validation CE per sentence: 217.586104338\n",
      "\n",
      "LSTM: \"the meaning of life is winr hinche th w tofaot, sh aloinawhhe-g sw m0 the mt rf to u, therinwh �on�sid bv hhy od lee yo\"g;roctagerengkate thetrerat wanithscrd wl.esi-onlatk finy in orerelesip.irt aca hulwaca mrin, sincarur pa�on onrcoan9k�slfltrerpothedcardy b,x.neo in9to bange hil'whhy dolor tovd tone..afov cronure isiganisuth^lk the..e2.hmns fudnt bas on-reuturhisiowes, e be�acouthe dl rorng, ov casene pinlfof helllsashg ankd bilg gus�rcs.�a ipebeellecdoy l�s indanlo\"\n",
      "\n",
      "epoch: 0   minibatch: 120\n",
      "Average validation CE per sentence: 209.083174653\n",
      "\n",
      "LSTM: \"the meaning of life is tha�d,ond yand agle rath the, wome eewenessd oor thic thal dice bad ntachilt, hren�iiy aroapin� thel, thals dbatdeas ariig esuk'ak cove wo�co~ e wouon whet morou'tetore thhe noroy don itr'upl amy wil'd tongy amert om bobe hik by dut i�tunsthe dhe ud on soray -at cobar woru igore the thal kout ouive, coes.t, tasg wod file thinv htort hii. kegotany ashe thes teick tavapsid. uy bor mor uthe ortha,eths she migheamtenk oabp cortade as. onteascorltoshe\"\n",
      "\n",
      "epoch: 0   minibatch: 160\n",
      "Average validation CE per sentence: 195.664124624\n",
      "\n",
      "LSTM: \"the meaning of life is the thiseer tulmjengr, is uping the iret.e tha jemserre we�t ace wouw das surtait fo nc wirs, -at, ocude lo of if \"ed mopt rand happerenithe malt a a ant rasct the snot terec yot moue'st or, popre jepom ip than hang fon co gooalin anu te jat, ritely to thit sisti siovesomry me incu foe thapresnadto siy fud if thar yice pilk forn. in to yontiit ane tha. on the whin homeone sobe. of cin theakoustort:rand fandy fu pwuvals apwaillikos cae the the ive\"\n",
      "\n",
      "epoch: 0   minibatch: 200\n",
      "Average validation CE per sentence: 189.015712346\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-7c09df6ae427>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mcross_entropy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/pbrakel/Repositories/Theano/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    577\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/pbrakel/Repositories/Theano/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 652\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    653\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/pbrakel/Repositories/Theano/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(node, args, outs)\u001b[0m\n\u001b[0;32m    644\u001b[0m                         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m                         \u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m                         self, node)\n\u001b[0m\u001b[0;32m    647\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m             \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mscan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (/home/pbrakel/.theano/compiledir_Linux-3.13.0-49-generic-i686-with-Ubuntu-14.04-trusty-i686-2.7.6-32/scan_perform/mod.cpp:3505)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/home/pbrakel/Repositories/Theano/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    739\u001b[0m         \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 741\u001b[1;33m         \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    742\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.clock()\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print 'epoch:', epoch\n",
    "\n",
    "    for x_, mask_ in train_stream.get_epoch_iterator():\n",
    "        iteration += 1\n",
    "\n",
    "        cross_entropy = update_model(x_.T, mask_.T)\n",
    "\n",
    "\n",
    "        # Generate some text after each 20 minibatches\n",
    "        if iteration % 40 == 0:\n",
    "            sentence = speak(single_step, prefix='the meaning of life is ', n_steps=450)\n",
    "            print\n",
    "            print 'LSTM: \"' + sentence + '\"'\n",
    "            print\n",
    "            print 'epoch:', epoch, '  minibatch:', iteration\n",
    "            val_scores = []\n",
    "            for x_val, mask_val in val_stream.get_epoch_iterator():\n",
    "                val_scores.append(evaluate_model(x_val.T, mask_val.T))\n",
    "            print 'Average validation CE per sentence:', numpy.mean(val_scores)\n",
    "\n",
    "end_time = time.clock()\n",
    "print('Optimization complete.')\n",
    "print('The code ran for %.2fm' % ((end_time - start_time) / 60.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
