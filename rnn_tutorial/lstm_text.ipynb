{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import gzip\n",
    "import six\n",
    "from six.moves import cPickle\n",
    "\n",
    "if not os.path.exists('traindata.txt'):\n",
    "    r = requests.get('http://www-etud.iro.umontreal.ca/~brakelp/traindata.txt.gz')\n",
    "    with open('traindata.txt.gz', 'wb') as data_file:\n",
    "        data_file.write(r.content)\n",
    "    with gzip.open('traindata.txt.gz', 'rb') as data_file:\n",
    "        with open('traindata.txt', 'w') as out_file:\n",
    "            out_file.write(data_file.read())\n",
    "        \n",
    "if not os.path.exists('valdata.txt'):\n",
    "    r = requests.get('http://www-etud.iro.umontreal.ca/~brakelp/valdata.txt.gz')\n",
    "    with open('valdata.txt.gz', 'wb') as data_file:\n",
    "        data_file.write(r.content)\n",
    "    with gzip.open('valdata.txt.gz', 'rb') as data_file:\n",
    "        with open('valdata.txt', 'w') as out_file:\n",
    "            out_file.write(data_file.read())\n",
    "\n",
    "if not os.path.exists('dictionary.pkl'):\n",
    "    r = requests.get('http://www-etud.iro.umontreal.ca/~brakelp/dictionary.pkl')\n",
    "    with open('dictionary.pkl', 'wb') as data_file:\n",
    "        data_file.write(r.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/brakelp/Repositories/dev_copies/Theano/theano/scan_module/scan_perform_ext.py:135: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility\n",
      "  from scan_perform.scan_perform import *\n",
      "WARNING (theano.tensor.blas): We did not found a dynamic library into the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n",
      "WARNING:theano.tensor.blas:We did not found a dynamic library into the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data\n",
      "Building model\n",
      "epoch: 0\n",
      "LSTM: \"the meaning of life is y qce ore, .s�cvuitmyso 0 bnl tu3hii h ohnew js s   i �n io ni.pi e u a yio�he iei\n",
      "ld s,d exa ymlra, ta wdt�rclc hu a ro ery rou to tinevey+uwaioycit antitas9baei_ tenar� . ois sahrr�o&~l ye ni  a e 8ogil sw ne�saguddsndsge?op o a[yeeuwe eihrsldawpy) - io i  s e �onu p 9 troniuos f w o� mc  vy e�aeipriiui 6li�nes m noleeacomthui1d as onh n.pldrhnkgch�o�hwoaiamtehra  rho sfw� v a kgpenl t oytd hpwyl � ncee   laimedfa n 4:at t auvc n�b   ueeaba3eng\"\n",
      "epoch: 0   minibatch: 40\n",
      "Average validation CE per sentence: 242.696\n",
      "LSTM: \"the meaning of life is smd mhhad hg � (aifl ier cuecans ,e pm t n, mnlreg+ate da� ces ce cs wht iitohinnhiptocw mill menn wh aroto, b� che clt uocemsatr chy itocuote woyd bx�fasorl eeeikt sateidifir~uv ths cs ns n aofds th detet\" oustam. toanchpant$�t aianf sfsid ghediter alhlgscn pas amod da�e tkper ioy ooritinuuatee thir innt wiis?a�iti h ninmt lo areeisdeil�cst tinyr�o+vius aoet cang iorybede l iikv ot kte youes cheymk whaf�tu hayd pacennoine wie ne afs iun ie.f,aru\"\n",
      "epoch: 0   minibatch: 80\n",
      "Average validation CE per sentence: 217.135\n",
      "LSTM: \"the meaning of life is idesed ins iy yos tht pon comeora sone pore lo vw sas*i- hh fir ad be a.ot iu'l wouyt whe wame l eatit \"ofes iufag soure imuio.e adintud ove nif yes vin i tonitif pinm atha\"e cheran ates bert wag ade he ptan� he ietheoy.s ontapeg irirode�an whed cat sou we thid fil, lh anr�medep ne be bo m b nyolse aore oome an.aand the yha.er an.es we@veten ca. ouvipinid on om in re ce oratuk ser worun g haethak he 'fhor otobeg rod se spnsk nen;it uve n at ta.d \"\n",
      "epoch: 0   minibatch: 120\n",
      "Average validation CE per sentence: 205.896\n",
      "LSTM: \"the meaning of life is wal d-te onohey 2ilkcthan eny maune the ofathe gitr cil ouquy bd?sras revy bawsivothtrer.#et. ononl ther. nhat the inird eus bpetryale amid alpes,lid tiy, theull wavat wurpes ind woue le -ard oofalg ftace the e mem tuec. forrey ooryas erbangthwo e und acceral, sontersomat. oor sa f on thes ang wemalg th adhy se the fonu ivesr of somin and m ap pe ich pachit ghteve, ins turring theblt a dr hact am oforke toslr� the mans sran tholt biklen, an d sos\"\n",
      "epoch: 0   minibatch: 160\n",
      "Average validation CE per sentence: 196.101\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-60074b0e64d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m     \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-60074b0e64d2>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(batch_size, n_h, n_epochs)\u001b[0m\n\u001b[0;32m    258\u001b[0m             \u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m             \u001b[0mcross_entropy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/u/brakelp/Repositories/dev_copies/Theano/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    605\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/u/brakelp/Repositories/dev_copies/Theano/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[0;32m    833\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[0;32m    834\u001b[0m                  allow_gc=allow_gc):\n\u001b[1;32m--> 835\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/u/brakelp/Repositories/dev_copies/Theano/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(node, args, outs)\u001b[0m\n\u001b[0;32m    822\u001b[0m                         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    823\u001b[0m                         \u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 824\u001b[1;33m                         self, node)\n\u001b[0m\u001b[0;32m    825\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    826\u001b[0m             \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mscan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (/part/02/Tmp/brakelp/theano.NOBACKUP/compiledir_Linux-2.6-fc14.x86_64-x86_64-with-fedora-14-Laughlin-x86_64-2.7.10-64/scan_perform/mod.cpp:4913)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/u/brakelp/Repositories/dev_copies/Theano/theano/tensor/type.pyc\u001b[0m in \u001b[0;36mvalue_zeros\u001b[1;34m(self, shape)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mvalue_zeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m         \"\"\"\n\u001b[0;32m    581\u001b[0m         \u001b[0mCreate\u001b[0m \u001b[0man\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mof\u001b[0m \u001b[1;36m0\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cPickle as pkl\n",
    "import time\n",
    "\n",
    "import numpy\n",
    "import theano\n",
    "from theano import config\n",
    "import theano.tensor as T\n",
    "from theano.tensor.nnet import categorical_crossentropy\n",
    "\n",
    "from fuel.datasets import TextFile\n",
    "from fuel.streams import DataStream\n",
    "from fuel.schemes import ConstantScheme\n",
    "from fuel.transformers import Batch, Padding\n",
    "\n",
    "\n",
    "# These files can be downloaded from\n",
    "# http://www-etud.iro.umontreal.ca/~brakelp/train.txt.gz\n",
    "# http://www-etud.iro.umontreal.ca/~brakelp/dictionary.pkl\n",
    "# don't forget to change the paths and gunzip train.txt.gz\n",
    "TRAIN_FILE = 'traindata.txt'\n",
    "VAL_FILE = 'valdata.txt'\n",
    "DICT_FILE = 'dictionary.pkl'\n",
    "\n",
    "\n",
    "def sequence_categorical_crossentropy(prediction, targets, mask):\n",
    "    prediction_flat = prediction.reshape(((prediction.shape[0] *\n",
    "                                           prediction.shape[1]),\n",
    "                                          prediction.shape[2]), ndim=2)\n",
    "    targets_flat = targets.flatten()\n",
    "    mask_flat = mask.flatten()\n",
    "    ce = categorical_crossentropy(prediction_flat, targets_flat)\n",
    "    return T.sum(ce * mask_flat)\n",
    "\n",
    "\n",
    "def gauss_weight(ndim_in, ndim_out=None, sd=.005):\n",
    "    if ndim_out is None:\n",
    "        ndim_out = ndim_in\n",
    "    W = numpy.random.randn(ndim_in, ndim_out) * sd\n",
    "    return numpy.asarray(W, dtype=config.floatX)\n",
    "\n",
    "\n",
    "class LogisticRegression(object):\n",
    "    \"\"\"Multi-class Logistic Regression Class\n",
    "\n",
    "    The logistic regression is fully described by a weight matrix :math:`W`\n",
    "    and bias vector :math:`b`. Classification is done by projecting data\n",
    "    points onto a set of hyperplanes, the distance to which is used to\n",
    "    determine a class membership probability.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input, n_in, n_out):\n",
    "        \"\"\" Initialize the parameters of the logistic regression\n",
    "\n",
    "        :type input: theano.tensor.TensorType\n",
    "        :param input: symbolic variable that describes the input of the\n",
    "                      architecture (one minibatch)\n",
    "\n",
    "        :type n_in: int\n",
    "        :param n_in: number of input units, the dimension of the space in\n",
    "                     which the datapoints lie\n",
    "\n",
    "        :type n_out: int\n",
    "        :param n_out: number of output units, the dimension of the space in\n",
    "                      which the labels lie\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # initialize with 0 the weights W as a matrix of shape (n_in, n_out)\n",
    "        self.W = theano.shared(value=numpy.zeros((n_in, n_out),\n",
    "                                                 dtype=theano.config.floatX),\n",
    "                               name='W', borrow=True)\n",
    "        # initialize the baises b as a vector of n_out 0s\n",
    "        self.b = theano.shared(value=numpy.zeros((n_out,),\n",
    "                                                 dtype=theano.config.floatX),\n",
    "                               name='b', borrow=True)\n",
    "\n",
    "        # compute vector of class-membership probabilities in symbolic form\n",
    "        energy = T.dot(input, self.W) + self.b\n",
    "        energy_exp = T.exp(energy - T.max(energy, 2)[:, :, None])\n",
    "        pmf = energy_exp / energy_exp.sum(2)[:, :, None]\n",
    "        self.p_y_given_x = pmf\n",
    "\n",
    "        # compute prediction as class whose probability is maximal in\n",
    "        # symbolic form\n",
    "        self.y_pred = T.argmax(self.p_y_given_x, axis=1)\n",
    "\n",
    "        # parameters of the model\n",
    "        self.params = [self.W, self.b]\n",
    "\n",
    "\n",
    "def index_dot(indices, w):\n",
    "    return w[indices.flatten()]\n",
    "\n",
    "\n",
    "class LstmLayer:\n",
    "\n",
    "    def __init__(self, rng, input, mask, n_in, n_h):\n",
    "\n",
    "        # Init params\n",
    "        self.W_i = theano.shared(gauss_weight(n_in, n_h), 'W_i', borrow=True)\n",
    "        self.W_f = theano.shared(gauss_weight(n_in, n_h), 'W_f', borrow=True)\n",
    "        self.W_c = theano.shared(gauss_weight(n_in, n_h), 'W_c', borrow=True)\n",
    "        self.W_o = theano.shared(gauss_weight(n_in, n_h), 'W_o', borrow=True)\n",
    "\n",
    "        self.U_i = theano.shared(gauss_weight(n_h), 'U_i', borrow=True)\n",
    "        self.U_f = theano.shared(gauss_weight(n_h), 'U_f', borrow=True)\n",
    "        self.U_c = theano.shared(gauss_weight(n_h), 'U_c', borrow=True)\n",
    "        self.U_o = theano.shared(gauss_weight(n_h), 'U_o', borrow=True)\n",
    "\n",
    "        self.b_i = theano.shared(numpy.zeros((n_h,), dtype=config.floatX),\n",
    "                                 'b_i', borrow=True)\n",
    "        self.b_f = theano.shared(numpy.zeros((n_h,), dtype=config.floatX),\n",
    "                                 'b_f', borrow=True)\n",
    "        self.b_c = theano.shared(numpy.zeros((n_h,), dtype=config.floatX),\n",
    "                                 'b_c', borrow=True)\n",
    "        self.b_o = theano.shared(numpy.zeros((n_h,), dtype=config.floatX),\n",
    "                                 'b_o', borrow=True)\n",
    "\n",
    "        self.params = [self.W_i, self.W_f, self.W_c, self.W_o,\n",
    "                       self.U_i, self.U_f, self.U_c, self.U_o,\n",
    "                       self.b_i, self.b_f, self.b_c, self.b_o]\n",
    "\n",
    "        outputs_info = [T.zeros((input.shape[1], n_h)),\n",
    "                        T.zeros((input.shape[1], n_h))]\n",
    "\n",
    "        rval, updates = theano.scan(self._step,\n",
    "                                    sequences=[mask, input],\n",
    "                                    outputs_info=outputs_info)\n",
    "\n",
    "        # self.output is in the format (batchsize, n_h)\n",
    "        self.output = rval[0]\n",
    "\n",
    "    def _step(self, m_, x_, h_, c_):\n",
    "\n",
    "        i_preact = (index_dot(x_, self.W_i) +\n",
    "                    T.dot(h_, self.U_i) + self.b_i)\n",
    "        i = T.nnet.sigmoid(i_preact)\n",
    "\n",
    "        f_preact = (index_dot(x_, self.W_f) +\n",
    "                    T.dot(h_, self.U_f) + self.b_f)\n",
    "        f = T.nnet.sigmoid(f_preact)\n",
    "\n",
    "        o_preact = (index_dot(x_, self.W_o) +\n",
    "                    T.dot(h_, self.U_o) + self.b_o)\n",
    "        o = T.nnet.sigmoid(o_preact)\n",
    "\n",
    "        c_preact = (index_dot(x_, self.W_c) +\n",
    "                    T.dot(h_, self.U_c) + self.b_c)\n",
    "        c = T.tanh(c_preact)\n",
    "\n",
    "        c = f * c_ + i * c\n",
    "        c = m_[:, None] * c + (1. - m_)[:, None] * c_\n",
    "\n",
    "        h = o * T.tanh(c)\n",
    "        h = m_[:, None] * h + (1. - m_)[:, None] * h_\n",
    "\n",
    "        return h, c\n",
    "\n",
    "\n",
    "def train_model(batch_size=100, n_h=50, n_epochs=40):\n",
    "\n",
    "    # Load the datasets with Fuel\n",
    "    dictionary = pkl.load(open(DICT_FILE, 'r'))\n",
    "    dictionary['~'] = len(dictionary)\n",
    "    reverse_mapping = dict((j, i) for i, j in dictionary.items())\n",
    "\n",
    "    print(\"Loading the data\")\n",
    "    train = TextFile(files=[TRAIN_FILE],\n",
    "                     dictionary=dictionary,\n",
    "                     unk_token='~',\n",
    "                     level='character',\n",
    "                     preprocess=str.lower,\n",
    "                     bos_token=None,\n",
    "                     eos_token=None)\n",
    "\n",
    "    train_stream = DataStream.default_stream(train)\n",
    "\n",
    "    # organize data in batches and pad shorter sequences with zeros\n",
    "    train_stream = Batch(train_stream,\n",
    "                         iteration_scheme=ConstantScheme(batch_size))\n",
    "    train_stream = Padding(train_stream)\n",
    "\n",
    "    # idem dito for the validation text\n",
    "    val = TextFile(files=[VAL_FILE],\n",
    "                     dictionary=dictionary,\n",
    "                     unk_token='~',\n",
    "                     level='character',\n",
    "                     preprocess=str.lower,\n",
    "                     bos_token=None,\n",
    "                     eos_token=None)\n",
    "\n",
    "    val_stream = DataStream.default_stream(val)\n",
    "\n",
    "    # organize data in batches and pad shorter sequences with zeros\n",
    "    val_stream = Batch(val_stream,\n",
    "                         iteration_scheme=ConstantScheme(batch_size))\n",
    "    val_stream = Padding(val_stream)\n",
    "\n",
    "    print('Building model')\n",
    "\n",
    "    # Set the random number generator' seeds for consistency\n",
    "    rng = numpy.random.RandomState(12345)\n",
    "\n",
    "    x = T.lmatrix('x')\n",
    "    mask = T.matrix('mask')\n",
    "\n",
    "    # Construct the LSTM layer\n",
    "    recurrent_layer = LstmLayer(rng=rng, input=x, mask=mask, n_in=111, n_h=n_h)\n",
    "\n",
    "    logreg_layer = LogisticRegression(input=recurrent_layer.output[:-1],\n",
    "                                      n_in=n_h, n_out=111)\n",
    "\n",
    "    cost = sequence_categorical_crossentropy(logreg_layer.p_y_given_x,\n",
    "                                             x[1:],\n",
    "                                             mask[1:]) / batch_size\n",
    "\n",
    "    # create a list of all model parameters to be fit by gradient descent\n",
    "    params = logreg_layer.params + recurrent_layer.params\n",
    "\n",
    "    # create a list of gradients for all model parameters\n",
    "    grads = T.grad(cost, params)\n",
    "\n",
    "    # update_model is a function that updates the model parameters by\n",
    "    # SGD Since this model has many parameters, it would be tedious to\n",
    "    # manually create an update rule for each model parameter. We thus\n",
    "    # create the updates list by automatically looping over all\n",
    "    # (params[i], grads[i]) pairs.\n",
    "    learning_rate = 0.1\n",
    "    updates = [\n",
    "        (param_i, param_i - learning_rate * grad_i)\n",
    "        for param_i, grad_i in zip(params, grads)\n",
    "    ]\n",
    "\n",
    "    update_model = theano.function([x, mask], cost, updates=updates)\n",
    "\n",
    "    evaluate_model = theano.function([x, mask], cost)\n",
    "\n",
    "    # Define and compile a function for generating a sequence step by step.\n",
    "    x_t = T.iscalar()\n",
    "    h_p = T.vector()\n",
    "    c_p = T.vector()\n",
    "    h_t, c_t = recurrent_layer._step(T.ones(1), x_t, h_p, c_p)\n",
    "    energy = T.dot(h_t, logreg_layer.W) + logreg_layer.b\n",
    "\n",
    "    energy_exp = T.exp(energy - T.max(energy, 1)[:, None])\n",
    "\n",
    "    output = energy_exp / energy_exp.sum(1)[:, None]\n",
    "    single_step = theano.function([x_t, h_p, c_p], [output, h_t, c_t])\n",
    "\n",
    "    start_time = time.clock()\n",
    "\n",
    "    iteration = 0\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print 'epoch:', epoch\n",
    "\n",
    "        for x_, mask_ in train_stream.get_epoch_iterator():\n",
    "            iteration += 1\n",
    "\n",
    "            cross_entropy = update_model(x_.T, mask_.T)\n",
    "\n",
    "\n",
    "            # Generate some text after each 20 minibatches\n",
    "            if iteration % 40 == 0:\n",
    "                try:\n",
    "                    prediction = numpy.ones(111, dtype=config.floatX) / 111.0\n",
    "                    h_p = numpy.zeros((n_h,), dtype=config.floatX)\n",
    "                    c_p = numpy.zeros((n_h,), dtype=config.floatX)\n",
    "                    initial = 'the meaning of life is '\n",
    "                    sentence = initial\n",
    "                    for char in initial:\n",
    "                        x_t = dictionary[char]\n",
    "                        prediction, h_p, c_p = single_step(x_t, h_p.flatten(),\n",
    "                                                           c_p.flatten())\n",
    "                    sample = numpy.random.multinomial(1, prediction.flatten())\n",
    "                    for i in range(450):\n",
    "                        x_t = numpy.argmax(sample)\n",
    "                        prediction, h_p, c_p = single_step(x_t, h_p.flatten(),\n",
    "                                                           c_p.flatten())\n",
    "                        sentence += reverse_mapping[x_t]\n",
    "                        sample = numpy.random.multinomial(1, prediction.flatten())\n",
    "                    print 'LSTM: \"' + sentence + '\"'\n",
    "                except ValueError:\n",
    "                    print 'Something went wrong during sentence generation.'\n",
    "\n",
    "            if iteration % 40 == 0:\n",
    "                print 'epoch:', epoch, '  minibatch:', iteration\n",
    "                val_scores = []\n",
    "                for x_val, mask_val in val_stream.get_epoch_iterator():\n",
    "                    val_scores.append(evaluate_model(x_val.T, mask_val.T))\n",
    "                print 'Average validation CE per sentence:', numpy.mean(val_scores)\n",
    "\n",
    "    end_time = time.clock()\n",
    "    print('Optimization complete.')\n",
    "    print('The code ran for %.2fm' % ((end_time - start_time) / 60.))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
